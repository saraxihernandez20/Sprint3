{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install requests_html"
      ],
      "metadata": {
        "id": "tq0pTsYz8xle"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cpWc4qtt8pGi",
        "outputId": "7f2770e3-c10f-42e0-a7ad-257d6fd44102"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting requests_html\n",
            "  Downloading requests_html-0.10.0-py3-none-any.whl (13 kB)\n",
            "Requirement already satisfied: bs4 in /usr/local/lib/python3.7/dist-packages (from requests_html) (0.0.1)\n",
            "Collecting parse\n",
            "  Downloading parse-1.19.0.tar.gz (30 kB)\n",
            "Collecting fake-useragent\n",
            "  Downloading fake-useragent-0.1.11.tar.gz (13 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from requests_html) (2.23.0)\n",
            "Collecting pyppeteer>=0.0.14\n",
            "  Downloading pyppeteer-1.0.2-py3-none-any.whl (83 kB)\n",
            "\u001b[K     |████████████████████████████████| 83 kB 756 kB/s \n",
            "\u001b[?25hCollecting w3lib\n",
            "  Downloading w3lib-2.0.1-py3-none-any.whl (20 kB)\n",
            "Collecting pyquery\n",
            "  Downloading pyquery-1.4.3-py3-none-any.whl (22 kB)\n",
            "Requirement already satisfied: appdirs<2.0.0,>=1.4.3 in /usr/local/lib/python3.7/dist-packages (from pyppeteer>=0.0.14->requests_html) (1.4.4)\n",
            "Requirement already satisfied: certifi>=2021 in /usr/local/lib/python3.7/dist-packages (from pyppeteer>=0.0.14->requests_html) (2022.6.15)\n",
            "Requirement already satisfied: importlib-metadata>=1.4 in /usr/local/lib/python3.7/dist-packages (from pyppeteer>=0.0.14->requests_html) (4.12.0)\n",
            "Collecting websockets<11.0,>=10.0\n",
            "  Downloading websockets-10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (112 kB)\n",
            "\u001b[K     |████████████████████████████████| 112 kB 39.1 MB/s \n",
            "\u001b[?25hCollecting urllib3<2.0.0,>=1.25.8\n",
            "  Downloading urllib3-1.26.12-py2.py3-none-any.whl (140 kB)\n",
            "\u001b[K     |████████████████████████████████| 140 kB 46.7 MB/s \n",
            "\u001b[?25hCollecting pyee<9.0.0,>=8.1.0\n",
            "  Downloading pyee-8.2.2-py2.py3-none-any.whl (12 kB)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.42.1 in /usr/local/lib/python3.7/dist-packages (from pyppeteer>=0.0.14->requests_html) (4.64.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=1.4->pyppeteer>=0.0.14->requests_html) (3.8.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=1.4->pyppeteer>=0.0.14->requests_html) (4.1.1)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.7/dist-packages (from bs4->requests_html) (4.6.3)\n",
            "Requirement already satisfied: lxml>=2.1 in /usr/local/lib/python3.7/dist-packages (from pyquery->requests_html) (4.9.1)\n",
            "Collecting cssselect>0.7.9\n",
            "  Downloading cssselect-1.1.0-py2.py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->requests_html) (2.10)\n",
            "Collecting urllib3<2.0.0,>=1.25.8\n",
            "  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n",
            "\u001b[K     |████████████████████████████████| 127 kB 46.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->requests_html) (3.0.4)\n",
            "Building wheels for collected packages: fake-useragent, parse\n",
            "  Building wheel for fake-useragent (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fake-useragent: filename=fake_useragent-0.1.11-py3-none-any.whl size=13502 sha256=aa7ae86e6cf7e90b8f9dab3fe0c36daa89e563fe67bc865dd04a05598921445a\n",
            "  Stored in directory: /root/.cache/pip/wheels/ed/f7/62/50ab6c9a0b5567267ab76a9daa9d06315704209b2c5d032031\n",
            "  Building wheel for parse (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for parse: filename=parse-1.19.0-py3-none-any.whl size=24591 sha256=03dbd4a3211556c2a9ff9e20e68bf497f59c99c074d4fea62d3cf7b100a879e5\n",
            "  Stored in directory: /root/.cache/pip/wheels/9c/aa/cc/f2228050ccb40f22144b073f15a2c84f11204f29fc0dce028e\n",
            "Successfully built fake-useragent parse\n",
            "Installing collected packages: websockets, urllib3, pyee, cssselect, w3lib, pyquery, pyppeteer, parse, fake-useragent, requests-html\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "Successfully installed cssselect-1.1.0 fake-useragent-0.1.11 parse-1.19.0 pyee-8.2.2 pyppeteer-1.0.2 pyquery-1.4.3 requests-html-0.10.0 urllib3-1.25.11 w3lib-2.0.1 websockets-10.3\n",
            "\n",
            "* * * APERTURA * * *\n",
            "El mínimo fue el 23 sept 2022 por valor de 3.47\n",
            "El máximo fue el 31 may 2022 por valor de 5.38\n",
            "\n",
            "\n",
            "* * * CIERRE * * *\n",
            "El mínimo fue el 23 sept 2022 por valor de 3.49\n",
            "El máximo fue el 31 may 2022 por valor de 5.32\n",
            "\n",
            "\n",
            "* * * VOLUMEN * * *\n",
            "El mínimo fue el 13 jul 2022 por valor de 725700.0\n",
            "El máximo fue el 03 jun 2022 por valor de 5644000.0\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Importar librerias a utilizar\n",
        "\n",
        "import pandas as pd\n",
        "import requests\n",
        "from requests_html import HTMLSession\n",
        "from bs4 import BeautifulSoup as bSoup\n",
        "\n",
        "# ==============================================\n",
        "\n",
        "# Funciones\n",
        "\n",
        "def findMin(df, column):\n",
        "  minimo = 100000000.0\n",
        "  fecha = ''\n",
        "  for idx in df.index:      # Por cada fila va a tomar el indice que sera almacenado en variable idx\n",
        "    if float(df[column][idx]) < minimo:\n",
        "      minimo = float(df[column][idx])\n",
        "      fecha = df['fecha'][idx]\n",
        "  return fecha, minimo\n",
        "\n",
        "\n",
        "\n",
        "def findMax(df, column):\n",
        "  maximo = -1000000000.0\n",
        "  fecha = ''\n",
        "  for idx in df.index:\n",
        "    if float(df[column][idx]) > maximo:   # Si tomando el valor flotante de df['apertura_max' = nombre de columna][idx = numero de fila en la tabla] '1231231'  pasa a ser FLOTANTE\n",
        "      maximo = float(df[column][idx])\n",
        "      fecha = df['fecha'][idx]\n",
        "  return fecha, maximo\n",
        "\n",
        "# ===============================================\n",
        "\n",
        "\n",
        "\n",
        "# Solicitud HTTP - GET = Consulta\n",
        "URL = \"https://es.finance.yahoo.com/quote/TEF/history?p=TEF&.tsrc=fin-srch\"\n",
        "rq = HTMLSession()    # Instancia de clase HTMLSession en variable rq\n",
        "pagina = rq.get(URL)  # Uso la instancia de rq para realizar la solicitud y almacenarlo en variable pagina  (Almacena todo el código HTMl de la URL proporcionada)\n",
        "\n",
        "# Codificación de contenido\n",
        "soup = bSoup(pagina.content, \"html.parser\")   # variable soup va a contener los resultados que reciba de BeatuifulSoup enviandole como parametros la pagina codificada y el tipo de decodificacion que se usara \n",
        "\n",
        "# Creación de listas = Columnas que voy a tener dentro de mi tabla (titulo de columna o encabezado)\n",
        "fecha = []\n",
        "apertura = []\n",
        "apertura_max = []\n",
        "apertura_min = []\n",
        "cierre = []\n",
        "volumen = []\n",
        "\n",
        "# Query ()COMENTARIO   \n",
        "elements = soup.find_all(\"tr\", class_=\"BdT\")  # ELEMENTS = LISTA []  Dentro de la variable elements voy a almacenar una busqueda dentro del html contenido en soup que sea su tag tr y su clase BdT\n",
        "# CONTENIDO DE ELEMENTS\n",
        "# [<tr ... . > CONTENIDO </tr>, <tr ... . > CONTENIDO </tr>, <tr ... . > CONTENIDO </tr>, <tr ... . > CONTENIDO </tr>, <tr ... . > CONTENIDO </tr>, <tr ... . > CONTENIDO </tr>,]\n",
        "# print(elements)\n",
        "\n",
        "\n",
        "# Llenado de listas desde html\n",
        "for e in elements:              # por cada valor en la lista de elements, almacene el valor actual en la variable e\n",
        "  row = e.find_all(\"span\")      # variable row CONTENDRÁ de e, busqueda de todos los elementos HTML que su tag sea SPAN\n",
        "  # Se debe verificar si la fecha no está repetida\n",
        "  #   en caso de estar repetida, saltará a la siguiente línea\n",
        "  if len(row) == 7:\n",
        "    fecha.append(str(row[0].contents).replace(\"['\",\"\").replace(\"']\",\"\"))   \n",
        "    apertura.append(str(row[1].contents).replace(',','.').replace(\"['\",\"\").replace(\"']\",\"\"))  \n",
        "    apertura_max.append(str(row[2].contents).replace(',','.').replace(\"['\",\"\").replace(\"']\",\"\"))\n",
        "    apertura_min.append(str(row[3].contents).replace(',','.').replace(\"['\",\"\").replace(\"']\",\"\"))\n",
        "    cierre.append(str(row[4].contents).replace(',','.').replace(\"['\",\"\").replace(\"']\",\"\"))\n",
        "    volumen.append(str(row[6].contents).replace('.','').replace(\"['\",\"\").replace(\"']\",\"\"))\n",
        "\n",
        "\n",
        "# Creación de diccionario para pandas\n",
        "dictionary = {\n",
        "    \"fecha\": fecha,\n",
        "    \"apertura\": apertura,\n",
        "    \"apertura_max\": apertura_max,\n",
        "    \"apertura_min\": apertura_min,\n",
        "    \"cierre\": cierre,\n",
        "    \"volumen\": volumen,\n",
        "}\n",
        "\n",
        "# ================ PANDAS\n",
        "# Creación dataframe\n",
        "data = pd.DataFrame(dictionary)\n",
        "\n",
        "# Manipulación de datos\n",
        "apMinFecha, apMinValue = findMin(data, 'apertura_min')\n",
        "apMaxFecha, apMaxValue = findMax(data, 'apertura_max')\n",
        "cierreMinFecha, cierreMinValue = findMin(data, 'cierre')\n",
        "cierreMaxFecha, cierreMaxValue = findMax(data, 'cierre')\n",
        "volumenMinFecha, volumenMinValue = findMin(data, 'volumen')\n",
        "volumenMaxFecha, volumenMaxValue = findMax(data, 'volumen')\n",
        "\n",
        "# Impresión de datos\n",
        "print('\\n* * * APERTURA * * *')\n",
        "print('El mínimo fue el '+str(apMinFecha)+' por valor de '+str(apMinValue))\n",
        "print('El máximo fue el '+str(apMaxFecha)+' por valor de '+str(apMaxValue)+'\\n')\n",
        "print('\\n* * * CIERRE * * *')\n",
        "print('El mínimo fue el '+str(cierreMinFecha)+' por valor de '+str(cierreMinValue))\n",
        "print('El máximo fue el '+str(cierreMaxFecha)+' por valor de '+str(cierreMaxValue)+'\\n')\n",
        "print('\\n* * * VOLUMEN * * *')\n",
        "print('El mínimo fue el '+str(volumenMinFecha)+' por valor de '+str(volumenMinValue))\n",
        "print('El máximo fue el '+str(volumenMaxFecha)+' por valor de '+str(volumenMaxValue)+'\\n')\n",
        "\n"
      ]
    }
  ]
}